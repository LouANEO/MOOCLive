This repository contains code to extract data from the mails extracted from the database of exchanges on the liste XXX@mail.com 
between january 2013 and may 2016.

## CONVERSION

The mails extracted directly from the database are registered in MIME format: we used the software TotalMailConverter to extract data from these files and create .txt files.

## FOLDER "DATA"

The folder "Data" can be downloaded to have the data and the structure of files needed to execute the following bash files.

It contains 8 folders:
- archivesMail (the initial data files)
- TxtData (data converted in .txt)
- Extraction (extracted data)
- DataMining (code for simple analysis on the data)
- Network (code to generate the network of mail exchanges) 
- Clustering (code and data for studying the division in clusters of the network)
- LanguageProcessing (code and data files for language processing)
- Results (results from analyses)

## HOWTO

### Data Extraction
Run the command ./runExtraction.sh $PATH (where $PATH is the path of the folder "Data" extracted previously)

This step performs an extraction of the data and merges them in a single .txt file

The code launches extractionAdresses.sh, extractionSubject.sh and merging.r, 3 codes located in "Data/Extraction".
It generates the following files in Data/Results:
- adresses.txt, containing 3 columns ($Folder $File $Sender)
- dates.txt, containing 3 columns ($Folder $File $DateOfEmission)
- sub.txt, containing 3 columns ($Folder $File $SubjectOfMail)
- data.txt containing all information

For more information, see README.md in "Data/Extraction"

### Data Mining
Run the command ./runDataMining.sh $PATH $BOOL (where $PATH is the path of the folder "Data" extracted previously)
- Set $BOOL to 0 if the clustering analyses has not been performed yet and 1 in the other case


This step performs a simple data mining analyse and study the temporal evolution of mail production.

The code launches runDataMining.r located in Data/DataMining and generates several graph and text files in Data/Results

For more information, see README.md in "Data/DataMining"

### Graph generation
Run the command ./runNetwork.sh $PATH (where $PATH is the path of the folder "Data" extracted previously)

This step generates a network from the threads of mails generated by the list users and extract a backbone of this network.

The code launches runNetwork.r located in Data/Network and generates "nodesAllNet.txt", "edgesAllNet.txt", "nodesWeighted.txt" and "edgesWeighted.txt" in Data/Network, 4 files describing the 2 networks generated by the function.
These files can be used directly in Gephi (available at https://gephi.org/) to visualize the graphs.

For more information, see README.md in "Data/Network"

### Clustering
Run the command ./runClustering.sh $PATH (where $PATH is the path of the folder "Data" extracted previously)

This step performs a cluster analyse of the backbone network previoulsy extracted.

We used the software "OSLOM", directly available on http://www.oslom.org/. The code requires the software to be installed directly in Data to work.
The code launches OSLOM to calculate the clusters and perform simple data manipulation on the files.
OSLOM results can be used directly in Gephi to visualize the results.

For more information, see README.md in "Data/Clustering"

### Language Processing
Run the command ./runLanguageProcessing.sh $PATH $GROUP $LANGUAGE
- $PATH is the path of the folder "Data" extracted previously
- $GROUP needs to be set to the number of the cluster analysed
- $LANGUAGE gives the language in which the analyse is performed (french for this study)

This step performs a text mining anlyse of the subjects of mails posted by the members of a group identified previoulsy.
Some R packages are needed: 
- stringr (https://cran.r-project.org/web/packages/stringr/)
- tm (https://cran.r-project.org/web/packages/tm/)
- wordcloud (https://cran.r-project.org/web/packages/wordcloud/) 
- RColorBrewer (https://cran.r-project.org/web/packages/RColorBrewer/).

The code run constructBase.r and traceCloud.r in Data/LanguageProcessing to generate a wordcloud of the group most commonly used words.

For more information, see README.md in "Data/LanguageClustering"
